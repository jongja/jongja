========================
## Earliest Eligible Virtual Deadline First (EEVDF) 알고리즘 요약

이 논문은 **시간 공유 자원**에 대한 새로운 **비례 공유 할당 알고리즘**인 EEVDF를 제안하고 분석합니다. 핵심 내용은 다음과 같습니다.

*   **비례 공유 할당:** 각 클라이언트에게 **가중치**를 부여하여 자원의 상대적인 점유율을 결정합니다. 즉, 가중치가 높은 클라이언트는 더 많은 자원을 할당받습니다.
*   **공정성 정의:** 이상적인 시스템(자원이 매우 작은 시간 간격으로 할당되는 시스템)에서의 공정성을 정의하고, 실제 시스템에서 클라이언트가 받아야 할 서비스 시간과 실제로 받는 서비스 시간의 차이가 **시간 양자(time quantum) 크기(q)**로 제한됨을 보장합니다.
*   **동적 운영 지원:** 클라이언트의 참여, 종료, 가중치 변경과 같은 동적인 상황을 지원합니다.
*   **효율적인 구현:** **확장된 이진 탐색 트리** 자료 구조를 사용하여 이러한 동적 운영을 O(log n) 시간 복잡도로 효율적으로 구현합니다 (n은 자원 경쟁 클라이언트 수).
========================
이 논문은 운영체제에서 경쟁하는 클라이언트 간의 자원 할당 문제에 대한 해결책을 제시하고 있으며, 특히 멀티미디어와 같은 실시간 애플리케이션의 요구사항을 충족시키는 스케줄링 알고리즘 설계에 초점을 맞추고 있습니다. 기존의 스케줄러들을 크게 비례 공유 스케줄러와 실시간 기반 스케줄러로 분류하고, 각 방식의 특징과 장단점을 설명합니다.

**핵심 내용 요약:**

*   **자원 할당의 중요성**: 현대 운영체제에서 자원을 효율적이고 정확하게 할당하는 것은 매우 중요한 문제이며, 특히 실시간 제약 조건이 있는 멀티미디어 애플리케이션의 등장으로 그 중요성이 더욱 커지고 있습니다.
*   **비례 공유 스케줄러**: 각 클라이언트에게 가중치를 부여하여 자원을 분배하는 방식으로, 유연성이 높고 과부하 상황에서 성능 저하가 적은 편입니다.
*   **실시간 기반 스케줄러**: 이벤트 기반 모델을 사용하여 각 이벤트의 마감시간을 보장하는 방식으로, 멀티미디어와 같이 시간 제약이 중요한 애플리케이션에 더 나은 성능을 제공합니다.
*   **실시간 스케줄러의 한계**: 배치(batch) 애플리케이션에는 적용하기 어렵고, 엄격한 허용 정책으로 인해 사용자가 새로운 애플리케이션을 실행하기 어려울 수 있습니다.
*   **일반적인 스케줄러의 접근 방식**: 연속적인 미디어 스케줄링을 위해 실시간 스케줄링 방식을 사용하면서도, 배치 애플리케이션 스케줄링을 위해 기존 알고리즘(라운드 로빈 등)을 함께 사용하는 경우가 많습니다.
========================
이 논문은 기존 스케줄러의 한계를 극복하고, 실시간성과 공정성을 동시에 보장하는 새로운 스케줄러인 EEVDF(Earliest Eligible Virtual Deadline First)를 제안합니다.

**핵심 내용 요약:**

*   **기존 스케줄러의 문제점:** 동적인 환경에서 유연성이 부족하며, 애플리케이션 종료 시 자원 분배가 어렵습니다.
*   **EEVDF 스케줄러의 특징:**
    *   비율 공유 스케줄러의 장점을 유지하면서 서비스 시간에 대한 강력한 실시간성 보장
    *   연속 미디어, 인터랙티브, 배치 애플리케이션 스케줄링을 위한 통합된 접근 방식 제공
    *   가상 시간 개념을 사용하여 이상적인 유체 기반 시스템에서의 작업 진행 상황 추적
*   **EEVDF 스케줄러의 작동 방식:**
    *   각 클라이언트에게 자원 점유율을 결정하는 가중치를 부여
    *   클라이언트의 요구 사항을 자원 요청 시퀀스로 변환
    *   클라이언트의 점유율과 서비스 시간을 기반으로 가상 시작 시간(eligible time)과 가상 마감 시간(deadline)을 할당
    *   가상 시작 시간이 현재 가상 시간보다 빠르고, 가상 마감 시간이 가장 빠른 요청부터 처리
*   **EEVDF 스케줄러의 장점:**
    *   유연하고 정확한 비율 공유 자원 할당 메커니즘 제공
    *   티켓, 통화, 프로세서 용량 예약과 같은 상위 수준 자원 추상화 지원
    *   티켓 전송 및 소멸과 같은 동적 작업 효율적으로 구현
*   **논문의 구성:** EEVDF 알고리즘, 동적 시스템에서의 공정성 개념, EEVDF 알고리즘 구현 전략, 공정성 분석, 관련 연구 검토, 결론 순으로 구성됩니다.
========================
이 페이지에서는 공유 자원 할당 모델과 관련된 내용을 설명하고 있습니다. 핵심 내용은 다음과 같습니다.

*   **기본 모델**: 클라이언트는 자원을 시간 양(time quantum) 단위로 할당받아 사용하며, 시간 양을 전부 사용하거나 만료 전에 자원을 반환할 수 있습니다. 이 모델은 프로세서나 통신 대역폭 공유와 같은 전통적인 자원 공유 메커니즘을 반영합니다.
*   **시간 양의 예시**: CPU 스케줄러가 프로세스에 CPU 시간을 할당하거나, 통신 스위치가 패킷 단위로 세션을 다중화하는 경우를 예시로 들 수 있습니다. 패킷 전송은 중단될 수 없으므로, 시간 양은 최대 길이 패킷을 전송하는 데 필요한 시간이 됩니다.
*   **가중치 기반 자원 할당**: 각 클라이언트에는 가중치가 부여되어 자원의 상대적 점유율을 결정합니다. 점유율은 해당 클라이언트의 가중치와 활성 상태인 모든 클라이언트 가중치 합의 비율로 계산됩니다.
*   **이상적인 공정 시스템**: 클라이언트의 점유율이 일정하게 유지된다면, 해당 클라이언트는 점유율에 시간 간격을 곱한 만큼 자원을 사용할 수 있어야 합니다. 하지만 실제로는 시간 양의 크기 때문에 완벽하게 공정한 할당이 어렵습니다.
*   **서비스 시간 지연(Service Time Lag)**: 클라이언트가 받아야 할 서비스 시간과 실제로 받은 서비스 시간의 차이를 의미합니다. 이는 양자화로 인해 발생하며, 스케줄링 오버헤드나 작업 중단 불가능성 등의 이유로 시간 양을 무한히 작게 설정할 수 없기 때문입니다.
========================
## 논문 요약: 비례적 자원 할당 알고리즘 (EEVDF)

이 페이지에서는 비례적 자원 할당 알고리즘을 설명하고, 서비스 시간 지연을 주요 파라미터로 사용하며, EEVDF 알고리즘의 작동 방식과 주기적 작업 스케줄링과의 유사점 및 차이점을 설명합니다.

**핵심 내용:**

*   **서비스 시간 지연 (Service Time Lag):** 처리량 정확도와 시스템 예측 가능성을 결정하는 핵심 파라미터로, 비례적 자원 할당 알고리즘을 특징짓는 데 사용됩니다. 수식 `l(t) = S(t0; t)`로 표현됩니다.
*   **EEVDF 알고리즘:** 클라이언트는 자원 접근을 위해 필요한 서비스 시간의 길이를 명시하는 요청을 발행해야 합니다. 요청이 완료되면 새로운 요청을 발행하거나 비활성 상태가 됩니다.
*   **요청 길이와 시스템 오버헤드:** 짧은 요청은 할당 정확도를 높이지만 시스템 오버헤드를 증가시키고, 긴 요청은 그 반대입니다. 클라이언트는 이를 조정하여 정확도와 오버헤드 사이의 균형을 맞출 수 있습니다.
*   **주기적 작업 스케줄링과의 비교:** 주기 T와 최대 서비스 시간 r로 정의되는 주기적 작업 스케줄링과 유사하게, EEVDF는 요청 시간 t와 지속 시간 r을 기반으로 이상적인 시스템에서 요청된 서비스 시간을 받아야 하는 시간 d를 계산합니다.
*   **모델의 차이점:** 실시간 시스템에서는 외부 이벤트의 결과로 요청이 생성되는 반면, EEVDF 모델에서는 클라이언트가 요청을 시작합니다.
========================
## 논문 요약 정리

이 논문은 가상 시간을 사용하여 서비스 시간을 관리하는 알고리즘을 제시하고 있습니다. 핵심 내용은 다음과 같습니다.

*   **요청 생성**: 요청은 외부 이벤트(클라이언트가 경쟁에 참여) 또는 내부 이벤트(현재 요청 완료 후 새 요청 생성)의 결과로 생성됩니다. 이는 이벤트 기반 애플리케이션과 배치 애플리케이션 모두를 지원합니다.
*   **가상 시간**: 시스템 가상 시간은 활성 클라이언트의 가중치 합계에 반비례하는 속도로 증가합니다. 경쟁이 심화되면 가상 시간이 느려지고, 경쟁이 줄어들면 가상 시간이 빨라집니다. 즉, 가상 시간은 모든 활성 클라이언트를 "수용"하도록 조정됩니다.
*   **서비스 시간 계산**: 클라이언트 i가 \[t1, t2) 구간에서 받아야 할 서비스 시간은 Si(t1, t2) = wi \* (V(t2) - V(t1))로 표현됩니다. 여기서 wi는 클라이언트 i의 가중치이고, V(t)는 시간 t에서의 가상 시간입니다.
*   **적격 시간(Eligible Time)**: 각 요청에 대해 적격 시간 e와 마감 시간 d를 할당합니다. 클라이언트가 새 요청을 시작할 때, 해당 요청의 적격 시간 e는 이상적인 시스템에서 클라이언트가 받아야 할 서비스 시간과 실제 시스템에서 이미 받은 서비스 시간이 같아지는 시점으로 설정됩니다.
*   **지연(Lag) 조정**: 클라이언트가 이미 받아야 할 서비스 시간보다 더 많은 시간을 받았다면(음수 지연), 새 요청은 적격 시간이 될 때까지 기다려야 합니다. 반대로, 덜 받았다면(양수 지연), 새 요청은 즉시 적격하게 됩니다. 이를 통해 서비스 시간을 초과한 클라이언트는 속도를 늦추고, 부족한 클라이언트는 따라잡을 기회를 얻게 됩니다.
========================
다음은 EEVDF(Earliest Eligible Virtual Deadline First) 알고리즘에 대한 설명입니다.

*   **가상 시간(Virtual Time) 기반 스케줄링:** EEVDF는 실제 시간 대신 가상 시간을 사용하여 스케줄링 결정을 내립니다. 이는 미래의 시스템 부하 변동성을 고려하기 어렵기 때문에, 가상 시간을 통해 스케줄링의 유연성을 확보하기 위함입니다.

*   **적격 시간과 데드라인:** 요청의 적격 시간(eligible time)은 요청이 처리될 수 있는 시작 시간을 의미하며, 데드라인(deadline)은 요청이 완료되어야 하는 마감 시간을 의미합니다. EEVDF는 각 요청에 대해 가상 적격 시간과 가상 데드라인을 계산합니다.

*   **EEVDF 알고리즘:** 가상 데드라인이 가장 빠른 요청부터 처리합니다. 이는 각 클라이언트에게 할당된 서비스 시간을 기준으로 공정성을 보장하기 위함입니다.

*   **가변적인 서비스 시간 처리:** EEVDF는 클라이언트가 요청한 서비스 시간을 항상 전부 사용하지 않을 수 있다는 점을 고려합니다. 클라이언트가 요청한 시간보다 적게 사용하면, 다음 요청의 가상 적격 시간을 앞당겨 공정성을 유지합니다.

*   **비균일 퀀타 지원:** EEVDF는 클라이언트마다 다른 길이의 시간 퀀타(time quanta)를 할당하는 것을 지원합니다. 이는 각 클라이언트의 요구 사항에 맞춰 자원 할당의 유연성을 높이기 위함입니다.
========================
## 논문 요약 (페이지 0-7)

**주요 내용:** EEVDF(Earliest Eligible Virtual Deadline First) 스케줄링 알고리즘을 설명하고, 클라이언트의 가중치와 요청 길이에 따른 스케줄링 과정을 예시를 통해 보여준다.

**핵심 문장:**

*   EEVDF 스케줄링은 클라이언트의 가중치에 따라 가상 시간을 계산하고, 이를 기반으로 요청의 마감 시간을 결정하여 스케줄링한다.
*   클라이언트가 요청한 서비스 시간을 전부 사용하지 않는 경우, 실제 사용 시간을 고려하여 다음 요청의 가상 시작 시간을 계산한다.
*   예시에서는 두 클라이언트의 가중치와 요청 길이를 설정하고, 시간 양자(time quantum)를 단위 크기로 하여 EEVDF 스케줄링이 어떻게 동작하는지 구체적으로 보여준다.

**쉬운 설명:**

EEVDF 스케줄링은 여러 사용자가 서버 자원을 나눠 쓸 때, 각 사용자에게 공정하게 자원을 배분하는 방법 중 하나입니다. 각 사용자에게는 '가중치'라는 중요도 점수가 주어지고, 이 점수에 따라 가상 시간이 계산됩니다. 사용자가 자원을 요청하면, 가상 시간을 기준으로 마감 시간이 정해지고, 마감 시간이 가장 빠른 요청부터 처리됩니다. 만약 사용자가 요청한 시간보다 적게 자원을 사용하면, 남은 시간을 고려하여 다음 요청의 시작 시간을 조절합니다. 그림 1은 이러한 과정을 두 사용자를 예시로 들어 설명하고 있습니다.
========================
## 논문 요약 (deadline 관련)

이 페이지에서는 동적 시스템에서의 공정성 문제와 이를 해결하기 위한 방안을 다룬다. 특히 클라이언트의 참여, 이탈, 가중치 변경과 같은 동적인 요소들이 시스템의 공정성에 미치는 영향에 대해 분석하고, 이를 해결하기 위한 정책을 제시한다.

**핵심 내용:**

*   **동적 시스템에서의 공정성 문제**: 클라이언트의 참여, 이탈, 가중치 변경은 이상적인 유체 시스템에서는 문제가 되지 않지만, 서비스 시간이 양자 단위로 할당되는 실제 시스템에서는 공정성에 영향을 미칠 수 있다.
*   **클라이언트 이탈의 영향**: 음의 지연(negative lag)을 가진 클라이언트가 이탈하면, 나머지 클라이언트들은 받아야 할 서비스 시간보다 적게 받게 된다. 즉, 한 클라이언트의 이득은 다른 클라이언트의 손실로 이어진다.
*   **손실 분배 방식**: 동적 작업이 발생할 때, 발생하는 이득 또는 손실은 활성 클라이언트들에게 가중치에 비례하여 분배된다. 이는 직관적일 뿐만 아니라 가상 시간(virtual time)을 업데이트하는 방식으로 쉽게 구현할 수 있다.
*   **Stride Scheduling과의 차이점**: 제시된 정책은 Waldspurger와 Weihl의 Stride Scheduling 알고리즘과 유사하지만, 클라이언트 이탈 또는 참여 시 가상 시간을 업데이트하는 방식에서 차이가 있다. Stride Scheduling에서는 가상 시간의 기울기만 업데이트하는 반면, 제시된 알고리즘에서는 가상 시간의 값 자체를 업데이트한다.
*   **예시**: 세 클라이언트가 활성화된 후 한 클라이언트가 이탈하는 상황을 예시로 들어, 이탈이 나머지 두 클라이언트에게 미치는 영향을 설명한다.
========================
이 페이지는 EEVDF(Earliest Eligible Virtual Deadline First) 스케줄링 알고리즘에서 클라이언트가 경쟁에서 이탈할 때 가상 시간을 어떻게 조정하여 남은 클라이언트 간의 공정성을 유지하는지 설명합니다.

**핵심 내용 요약:**

*   **클라이언트 이탈 시점:** 특정 시점(t)에 클라이언트가 이탈하면, EEVDF는 남아있는 클라이언트에게 서비스 시간을 재분배해야 합니다.
*   **서비스 시간 재분배:** 이탈한 클라이언트가 떠난 후, 남아있는 클라이언트들은 이탈한 클라이언트가 떠나기 전까지 받아야 했던 서비스 시간의 손실이나 이득을 가중치에 비례하여 분담합니다.
*   **가상 시간 업데이트:** EEVDF는 남아있는 클라이언트 간의 공정성을 유지하기 위해 가상 시간을 업데이트합니다. 이때, 가상 시간은 이탈한 클라이언트의 지연 시간(lag)에 비례하여 조정됩니다.
*   **지연 시간 계산:** 클라이언트의 지연 시간은 가상 시간과 실제 서비스 시간의 차이를 이용하여 계산됩니다. 이탈 시점에서의 지연 시간을 바탕으로 가상 시간을 조정함으로써, 남아있는 클라이언트들은 공정한 서비스 시간을 보장받을 수 있습니다.
*   **Work-conserving 알고리즘:** EEVDF는 work-conserving 알고리즘으로, 활성 클라이언트가 있는 동안에는 자원이 유휴 상태로 있지 않습니다. 즉, 시스템은 항상 작업을 처리하려고 노력합니다.
========================
이 페이지에서는 클라이언트가 경쟁에 참여하거나 떠날 때 가상 시간을 업데이트하는 규칙과, 클라이언트가 사용하지 못한 서비스 시간을 보상할지 여부에 대한 논의를 다룹니다.

**핵심 내용 요약:**

*   **클라이언트 이탈 시 래그 분배:** 클라이언트가 떠날 때 발생하는 래그(지연)는 남아있는 클라이언트들에게 비례적으로 분배되어 공정성을 유지합니다.
*   **가상 시간 업데이트 규칙:**
    *   클라이언트가 떠날 때: `V(t) = V(t) + lag_j(t) / (Σ w_i)` (여기서 `lag_j(t)`는 떠나는 클라이언트의 래그, `Σ w_i`는 활성 클라이언트 가중치의 합)
    *   클라이언트가 참여할 때: `V(t) = V(t) - lag_j(t) / (Σ w_i)` (여기서 `lag_j(t)`는 참여하는 클라이언트의 래그, `Σ w_i`는 활성 클라이언트 가중치의 합)
*   **서비스 시간 보존 속성:** 활성 클라이언트의 래그 합은 항상 0으로 유지됩니다. 이는 한 클라이언트가 할당량보다 더 많은 서비스 시간을 받으면, 다른 클라이언트는 그만큼 덜 받는다는 것을 의미합니다.
*   **가중치 변경:** 클라이언트의 가중치 변경은 클라이언트가 떠났다가 즉시 다시 참여하는 것과 동일하게 취급됩니다. 래그가 0인 클라이언트의 가중치를 변경하면 가상 시간은 변하지 않습니다.
*   **미사용 서비스 시간 보상 문제:** 클라이언트가 활동을 중단했다가 다시 활동할 때, 이전에 사용하지 못한 서비스 시간을 보상해 줄지 여부에 대한 명확한 해답은 없습니다. 보상하지 않으면 클라이언트가 장기간에 걸쳐 불이익을 받을 수 있고, 보상하면 다른 클라이언트에게 불이익을 줄 수 있습니다.
========================
## EEVDF 알고리즘 구현을 위한 세 가지 전략

이 페이지에서는 EEVDF 알고리즘을 구현하기 위한 세 가지 전략을 제시합니다. 각 전략은 클라이언트가 경쟁에 다시 참여할 때 발생하는 지연(lag)을 어떻게 처리할지에 대한 결정에 따라 달라집니다.

**전략 1:**

*   클라이언트는 언제든지 경쟁에서 나가거나 참여할 수 있으며, 지연 정도에 따라 재참여 시 불이익을 받거나 보상을 받습니다.
*   클라이언트가 시간 t에 경쟁에서 나가고 t'에 다시 참여하면, `lag(t) = lag(t')`으로 지연이 유지됩니다.
*   클라이언트의 참여, 이탈, 가중치 변경 등의 이벤트가 발생할 때마다 가상 시간(virtual time)이 업데이트됩니다.
*   이 전략은 클라이언트 활동의 여러 기간에 걸쳐 공정성을 유지하는 데 적합합니다.

**전략 2:**

*   전략 1과 유사하지만, 클라이언트가 경쟁에서 나간 후에는 지연이 유지되지 않습니다. 즉, 재참여하는 클라이언트는 지연이 0부터 시작합니다.
*   이 전략은 클라이언트의 활동을 유발하는 이벤트가 독립적인 시스템에 적합합니다. 이는 이벤트 처리 시간이 다른 이벤트 처리 시간과 독립적이라고 가정하는 실시간 시스템과 유사합니다.

**전략 3:**

*   클라이언트는 지연이 0일 때만 경쟁에서 나가거나 참여하거나 가중치를 변경할 수 있습니다.
*   따라서 동적인 작업이 발생할 때 가상 시간을 업데이트할 필요가 없습니다.
*   이 전략의 복잡성은 이벤트 발생 시 지연이 실제로 0인지 확인하는 데 있습니다.
*   모든 이벤트가 지연이 0인 클라이언트만 포함하도록 하기 위해, uid-ow 시스템에서 해당 시점에 가상 시간의 기울기를 업데이트해야 합니다.
*   클라이언트가 양의 지연을 가지고 경쟁에서 나갈 때 가상 시간의 기울기를 업데이트하는 것이 주요 문제입니다.
*   이 문제를 해결하기 위해, 시간 양자(time quantum) 동안에는 이벤트가 발생하지 않는다고 가정합니다.
*   클라이언트가 음의 지연을 가지고 경쟁에서 나가려고 할 경우, 지연이 0이 될 때까지 클라이언트를 지연시킵니다.
*   클라이언트가 요청한 전체 서비스 시간을 항상 사용하는 시스템에서는 클라이언트의 마지막 요청의 가상 마감 시간으로 uid-ow 시스템에서 클라이언트가 나가야 하는 가상 시간을 계산할 수 있습니다. 이는 Parekh와 Gallager가 Packet-by-Packet Generalized Processor Sharing 알고리즘에서 사용한 접근 방식입니다.
========================
다음은 제공된 논문 페이지의 요약입니다.

**1. Zero Length Request 처리:**

*   클라이언트의 negative lag (요청 마감 시간 초과) 문제를 해결하기 위해 zero length request를 사용합니다.
*   Zero length request는 클라이언트가 마감 시간을 넘겨 처리되도록 하여, negative lag를 non-negative lag로 변환합니다.
*   Virtual time이 연속적으로 변하는 시스템에서는 요청이 마감 시간 후 특정 time quantum 내에 완료됩니다.

**2. 남은 Service Time 처리:**

*   클라이언트가 마지막 요청을 완료하기 전에 떠날 경우, 남은 service time은 다른 활성 클라이언트에게 무상으로 랜덤하게 할당됩니다.
*   이는 클라이언트가 경쟁하는 동안 최소한 자신의 몫을 받도록 보장하기 위한 전략입니다.

**3. EEVDF 알고리즘의 Fairness 분석:**

*   EEVDF (Earliest Eligible Virtual Deadline First) 알고리즘의 service time lag에 대한 bound를 결정합니다.
*   Active client가 하나 이상 있는 동안에는 항상 eligible pending request가 존재합니다.
*   EEVDF 알고리즘은 work-conserving하며, active client가 있는 동안에는 resource가 idle 상태가 될 수 없습니다.

**4. Steady System 정의:**

*   Steady system은 발생하는 모든 event (클라이언트 참여, 종료, weight 변경)가 zero lag를 가진 클라이언트와 관련된 시스템입니다.
*   Steady system에서는 virtual time이 연속적이며, 이를 통해 client lag에 대한 tight bound를 결정할 수 있습니다.
*   Steady interval은 해당 interval에서 발생하는 모든 event가 zero lag를 가진 클라이언트와 관련된 interval입니다.
========================
## Lemma 요약

이 페이지는 EEVDF 알고리즘의 중요한 속성을 증명하는 Lemma와 Corollary를 제시합니다. 핵심 내용은 다음과 같습니다.

*   **Lemma 1:** 활성 클라이언트가 양의 지연(lag)을 가질 경우, 해당 클라이언트는 반드시 처리 가능한(eligible) 요청을 가지고 있습니다. 즉, 지연이 발생했다는 것은 시스템이 해당 클라이언트의 요청을 처리할 준비가 되었다는 의미입니다.
*   **Corollary 1:** 모든 활성 클라이언트의 지연 합이 0인 경우, 시스템에는 최소한 하나의 처리 가능한 요청이 존재합니다. 이는 시스템 내에서 지연이 발생한 클라이언트가 있다면, 그에 상응하는 처리 가능한 요청이 있다는 것을 의미합니다.
*   **Lemma 2:** 임의의 시점에서 모든 활성 클라이언트의 지연 합은 0입니다. 이는 시스템이 클라이언트들의 지연을 균형 있게 관리하고 있음을 나타냅니다.
*   **EEVDF 알고리즘의 Work-Conserving 속성:** Lemma 2와 Corollary 1로부터 EEVDF 알고리즘은 work-conserving 속성을 가짐을 알 수 있습니다. Work-conserving이란 시스템에 활성 클라이언트가 존재하는 한, 자원은 항상 사용 중임을 의미합니다. 즉, EEVDF 알고리즘은 자원을 낭비하지 않고 효율적으로 활용합니다.
========================
이 페이지는 귀납법을 사용하여 특정 방정식의 진실성을 증명하는 과정을 설명하고 있습니다. 증명의 핵심은 다음과 같습니다.

*   **귀납법의 기본**: 초기 조건에서 방정식이 성립함을 보이고, 특정 사건이 발생했을 때도 방정식이 유지됨을 증명합니다.
*   **주요 이벤트**: 클라이언트가 경쟁에 참여, 이탈, 또는 가중치를 변경하는 경우를 고려합니다. 또한, 이러한 이벤트가 없는 특정 시간 간격 동안 방정식이 유지되는지 확인합니다.
*   **클라이언트 참여**: 새로운 클라이언트가 참여할 때, 전체 가중치 합(W)을 고려하여 방정식이 여전히 성립함을 보입니다.
*   **클라이언트 이탈 및 가중치 변경**: 클라이언트가 이탈하거나 가중치를 변경하는 경우는 클라이언트 참여와 유사한 방식으로 증명됩니다. 가중치 변경은 클라이언트 이탈 후 재참여로 간주됩니다.
*   **이벤트 없는 시간 간격**: 이벤트가 없는 시간 간격 동안에는 클라이언트들의 지연(lag) 합이 0으로 유지됨을 증명합니다. 이를 위해 리소스가 해당 시간 간격 동안 계속 사용 중임을 보여줍니다. 만약 리소스가 유휴 상태가 되면 모순이 발생함을 이용하여 증명합니다.
========================
## 논문 요약 정리

이 페이지는 시스템 내 요청 처리 지연 시간의 상한을 분석하고, 특정 조건 하에서 요청이 얼마나 늦게 처리될 수 있는지를 증명합니다.

**핵심 내용:**

*   **Steady System에서의 최대 지연:** Steady system에서 클라이언트 k의 요청은 데드라인 d를 넘어서 d + q 시간 안에 완료됨을 증명합니다. 여기서 q는 time quantum의 크기입니다. 즉, 최악의 경우에도 time quantum 크기만큼만 데드라인을 넘길 수 있습니다.
*   **집합 B와 C의 활용:** 데드라인 d 시점에서 활성 클라이언트를 두 그룹(B, C)으로 나눕니다. B는 \[e, d] 구간에 데드라인이 있는 클라이언트, C는 그 외 클라이언트입니다. 이를 통해 특정 시점 t에서 클라이언트 C에 time quantum이 할당되는 경우를 분석합니다.
*   **Case 분석:** time quantum 할당 시점 t가 존재하는 경우(t 존재)와 그렇지 않은 경우(t 부재)로 나누어 증명을 진행합니다. t가 존재하는 경우, t가 \[e, d) 구간에 속하는지 또는 t < e 인지에 따라 추가적인 분석을 수행합니다.
*   **집합 D의 도입:** t < e인 경우, \[t, d) 구간에 데드라인을 가진 eligible 요청을 가진 클라이언트 집합 D를 정의합니다. 이를 통해 time quantum 할당 시점 t 이후에 경쟁에 참여하는 클라이언트를 고려합니다.
*   **요청 완료 보장:** 클라이언트 j가 S\_j(e\_j, d\_j) 만큼의 서비스 시간을 받으면 \[e\_j, d\_j) 구간의 모든 요청이 완료됨을 설명합니다. 이를 통해 \[t, d) 구간의 데드라인을 가진 모든 요청을 처리하는 데 필요한 서비스 시간을 계산합니다.
========================
## 논문 페이지 요약

이 페이지는 EEVDF 스케줄링 알고리즘의 성능 분석에 대한 내용으로, 특정 조건 하에서 데드라인을 놓치는 경우가 발생하지 않음을 증명하는 과정을 설명합니다.

**핵심 내용 요약:**

*   **클라이언트 집합 분리:** 현재 요청(데드라인 d)을 가진 클라이언트 k와 관련된 클라이언트 집합을 B(데드라인이 [e, d] 구간에 있는 클라이언트)와 C(그 외 클라이언트)로 나눕니다. D(t)는 시간 t에 데드라인이 [t, d) 구간에 있는 클라이언트 집합입니다.
*   **서비스 시간 분석:** 클라이언트 k의 요청이 완료되지 않은 상태에서, C에 속한 클라이언트는 k의 요청이 완료되기 전까지 서비스를 받지 못합니다. 따라서 t+q 부터 d+q 사이의 서비스 시간은 D에 속한 클라이언트에게만 할당됩니다.
*   **모순 증명:** D에 속한 클라이언트는 데드라인 dj가 있는 요청이 완료되면 더 이상 시간 퀀텀을 받지 않습니다. [t, d) 구간의 데드라인을 가진 모든 요청을 완료하는 데 필요한 서비스 시간은 d-t 보다 작으므로, 자원이 유휴 상태가 됩니다. 이는 EEVDF가 work-conserving이라는 사실과 모순됩니다.
*   **Case 2 (t가 존재하지 않는 경우):** 경쟁에 참여하는 첫 번째 클라이언트 시간을 t로 설정하고, 집합 C가 비어있으므로 t부터 d사이의 모든 시간 퀀텀은 D의 클라이언트에게 할당됩니다. 이 경우 클라이언트 k는 데드라인 d를 놓치지 않음을 보여줍니다.
========================
이 페이지는 steady interval 내에서 클라이언트의 지연 시간(lag)에 대한 상한(bound)을 제시하고, steady state에 도달하는 시스템에 대한 조건을 설명합니다.

**핵심 내용 요약:**

*   **Steady Interval 내의 부분 구간:** steady interval의 특정 부분 구간에서도 유사한 상한이 유지됨을 보여줍니다.
*   **Steady State 도달 조건:** non-zero lag를 가진 클라이언트가 참여, 이탈하거나 가중치를 변경할 수 있는 시스템은 결국 steady state에 도달합니다.
*   **Lemma 증명:** Lemma를 통해 특정 시간 `d` 이후에 클라이언트의 요청이 얼마나 빨리 처리되는지 증명합니다. 이는 active 클라이언트를 두 그룹(B, C)으로 나누어 분석하고, 각 그룹의 지연 시간을 고려하여 증명합니다.
*   **Theorem:** steady system에서 active 클라이언트의 지연 시간은 `r_max`와 `q`의 최댓값으로 제한됩니다. 여기서 `r_max`는 클라이언트가 발행한 요청의 최대 지속 시간을 나타냅니다.
*   **Tight Bound:** 제시된 상한은 점근적으로 tight(asymptotically tight)합니다. 즉, 이 상한은 실제 지연 시간을 매우 정확하게 나타냅니다.
========================
이 페이지는 클라이언트 k가 발행한 요청의 적격 시간(e), 마감 시간(d), 지속 시간(r) 간의 관계를 분석하고, 클라이언트의 지연 시간(lag)에 대한 상한 및 하한을 도출합니다.

**핵심 내용 요약:**

*   **지연 시간 감소 및 증가:** 클라이언트 k가 서비스를 받으면 지연 시간은 감소하고, 그렇지 않으면 증가합니다. 요청은 적격 시간 이전에 서비스되지 않으므로, 최소 지연 시간은 요청이 적격 시간이 되자마자 전체 서비스 시간을 받는 경우에 달성됩니다.
*   **최소 지연 시간:** 요청이 시간 `e + r` 내에 완료되면 최소 지연 시간은 `lag_k(e + r) >= -r`로 표현됩니다. 이는 클라이언트 지연 시간에 대한 하한을 나타내며, 활성 상태인 동안 `lag_k(t) >= -r_max`를 만족합니다.
*   **최대 지연 시간:** 최대 지연 시간은 가능한 한 늦게 전체 서비스 시간이 할당될 때 발생합니다. 보조정리에 따라 요청은 `d + q` 이내에 완료되므로, 클라이언트 k가 첫 번째 양자(quantum)를 받아야 하는 가장 늦은 시간은 `d + q - r`입니다.
*   **두 가지 경우 분석:** `r >= q`와 `r < q` 두 가지 경우를 고려하여 최대 지연 시간을 분석합니다.
*   **최대 지연 시간 상한:** 두 경우를 결합하여 클라이언트가 활성 상태인 동안 임의의 시간 t에서 `lag_k(t) < max(q, r_max)`를 만족한다는 결론을 도출합니다. 여기서 `q`는 양자 크기, `r_max`는 클라이언트 k가 발행한 요청의 최대 지속 시간입니다.
========================
이 페이지는 EEVDF 스케줄링 알고리즘의 성능 분석과 관련된 내용을 담고 있습니다. 특히, 클라이언트의 지연(lag)을 제한하는 경계(bound)가 얼마나 타이트한지, 그리고 요청의 크기와 시스템 오버헤드 간의 관계를 설명합니다.

**핵심 내용 요약:**

*   **지연 경계의 타이트함:** 특정 예시를 통해 `lag_k(t) > -r_max` 경계가 점근적으로 타이트함을 보입니다. 이는 클라이언트의 지연이 요청 크기에 비례하여 제한될 수 있음을 의미합니다.
*   **요청 크기와 시스템 오버헤드:** 짧은 요청은 더 나은 할당 정확도를 제공하지만, 시스템 오버헤드를 증가시킵니다. 반대로, 긴 요청은 오버헤드를 줄이지만 정확도가 떨어질 수 있습니다. 따라서 클라이언트 요구 사항에 따라 적절한 요청 크기를 선택하는 것이 중요합니다.
*   **EEVDF의 유연성:** EEVDF는 다양한 요구 사항을 가진 클라이언트를 수용하면서 각 클라이언트의 지연에 대한 타이트한 경계를 보장할 수 있습니다. 예를 들어, 계산 집약적인 작업은 긴 요청을 사용할 수 있고, 멀티미디어 응용 프로그램은 짧은 요청을 사용해야 합니다.
*   **시간 양자화(Time Quantum) 환경에서의 최적성:** 시간 양자 크기(q)보다 큰 요청이 없는 경우, 클라이언트의 지연은 `-q < lag_k(t) < q`로 제한됩니다. 이는 비례 공유(proportional share) 알고리즘에서 달성할 수 있는 최적의 경계입니다.
*   **보조정리(Lemma)를 통한 증명:** 어떠한 비례 공유 알고리즘에서도 클라이언트의 지연은 -q와 q 사이로 제한됨을 증명합니다. 이는 EEVDF가 시간 양자화 환경에서 지연을 최소화하는 데 효과적임을 시사합니다.
========================
## 페이지 내용 요약:

**1. 비례 지분 알고리즘의 한계:**

*   비례 지분(Proportional Share) 알고리즘이 특정 상한(q)보다 작은 값을 달성한다고 가정하면 모순이 발생한다.
*   이는 클라이언트가 받는 시간 양(time quanta)과 지연(lag) 사이의 관계를 통해 증명된다.
*   마찬가지로, 어떤 알고리즘도 -q보다 나은 하한을 달성할 수 없음을 보일 수 있다.

**2. 관련 연구 소개 및 스케줄링 알고리즘 분류:**

*   기존 스케줄링 알고리즘들을 크게 시간 종속 우선순위(Time-Dependent Priority), 실시간(Real-Time), 공정 큐잉(Fair Queueing), 비례 지분(Proportional Share)으로 분류한다.

**3. 시간 종속 우선순위 스케줄링 (Time-Dependent Priority Scheduling):**

*   **개념:** 프로세스에 CPU 시간을 할당하기 위해 우선순위 개념을 사용한다.
*   **정적 우선순위 방식의 문제점:** 높은 우선순위 프로세스가 낮은 우선순위 프로세스보다 절대적으로 우선하므로, 유연성이 떨어지고 기아(starvation) 현상이 발생할 수 있다.
*   **개선 시도:** 최근 CPU 사용량에 따라 프로세스 우선순위를 변경하여 공정성을 확보하려는 시도 (decay usage scheduling)가 있었다. (Unix BSD, System V 등에 구현)
*   **decay usage scheduling의 단점:** 짧은 시간 동안의 자원 할당에 대한 세밀한 제어가 어렵다.
*   **Time-Function Scheduling (TFS):** 클라이언트의 우선순위를 시간에 따라 변하는 함수로 정의한다. 클라이언트가 스케줄링되기를 기다리는 동안 우선순위가 선형적으로 증가하며, 스케줄링될 때 미리 정의된 값으로 초기화된다.
*   **TFS의 특징:** 클라이언트를 특성에 따라 분리된 클래스로 나누고, 각 클래스 내에서는 FCFS(First-Come, First-Served) 큐로 관리한다.
*   **TFS의 장점:** 자원 할당에 대한 효과적이고 유연한 제어를 제공하며, 클래스별 처리량 및 대기 시간 분산과 같은 스케줄링 목표를 달성할 수 있다.
*   **TFS의 단점:** 클라이언트 우선순위 업데이트 빈도에 따라 정확도가 달라지는데, 업데이트 작업이 비용이 많이 들어 정확도 향상에 제한이 있다.

**4. 실시간 시스템 (Real-Time Systems):**

*   **특징:** 엄격한 데드라인 보장이 필요한 중요한 시간 작업(critical time tasks)을 위해 개발되었다.
*   **작업 특징:** 특정 패턴으로 도착하는 이벤트 시퀀스로 특징지어진다.
========================
이 페이지는 주기적인 작업 스케줄링 알고리즘인 RM(Rate Monotonic)과 EDF(Earliest Deadline First)를 소개하고, 이들의 특징과 장단점을 분석합니다. 또한, 이 알고리즘들이 실시간 시스템 및 멀티미디어 애플리케이션 지원에 어떻게 활용되었는지 설명합니다.

**핵심 내용 요약:**

*   **RM(Rate Monotonic) 및 EDF(Earliest Deadline First) 알고리즘 소개:**
    *   RM은 작업 주기가 짧을수록 높은 우선순위를 부여하는 고정 우선순위 스케줄링 알고리즘입니다.
    *   EDF는 데드라인이 빠를수록 높은 우선순위를 부여하는 동적 우선순위 스케줄링 알고리즘입니다.
*   **RM과 EDF의 특징 및 장단점 비교:**
    *   EDF는 RM보다 프로세서 활용률이 높고 문맥 전환 오버헤드를 줄일 수 있지만, RM은 구현이 간단하고 과부하 시 우선순위가 높은 작업의 데드라인을 보장할 수 있습니다.
*   **실시간 시스템 및 멀티미디어 애플리케이션에서의 활용:**
    *   RM과 EDF는 기존 운영체제에 실시간 기능(연속적인 미디어 재생 등)을 추가하는 데 사용되었으며, 분산 멀티미디어 애플리케이션 플랫폼 설계 및 프로세서 용량 예약(processor capacity reserves)과 같은 고급 추상화 기술 개발에 활용되었습니다.
========================
다음 논문 페이지를 요약했습니다.

*   **일반적인 실시간 스케줄러의 한계:**
    *   일반적인 실시간 스케줄러는 연속 미디어, 인터랙티브, 배치 애플리케이션을 통합적으로 지원하지 못한다.
    *   실시간 스케줄러는 비례 공유 스케줄러에 비해 제약이 많고 유연성이 떨어진다. 예를 들어, 애플리케이션 종료 시 남은 자원을 다른 활성 애플리케이션에 효율적으로 재분배하기 어렵다.
*   **RBE(Rate-Based Execution)의 소개:**
    *   Jeffay와 Bennette는 멀티미디어 애플리케이션을 위한 새로운 추상화인 RBE를 제안했다.
    *   RBE는 x, y, d 세 가지 파라미터로 프로세스를 특징짓는다. 여기서 x는 y 시간 간격 동안 도착하는 이벤트 수, d는 이벤트 전달과 완료 사이의 최대 경과 시간을 나타낸다.
    *   RBE는 EEVDF와 유사하게 도착 시간이나 처리 시간 분포에 대한 가정을 하지 않는다.
*   **통합 스케줄러의 필요성:**
    *   Nieh와 Lam은 범용 운영체제에서 멀티미디어 애플리케이션을 지원하는 새로운 통합 프로세서 스케줄러를 개발했다.
    *   이 스케줄러는 각 클라이언트에 최소 실행률을 할당하고, 이를 연속 미디어 및 인터랙티브 애플리케이션의 시간 제약 조건과 배치 애플리케이션의 최소 허용 진행률로 변환한다.
    *   EEVDF와 유사하게 최소 실행률 개념을 사용하여 연속 미디어, 인터랙티브, 배치 애플리케이션을 통합적으로 스케줄링한다.
========================
## EEVDF와 Fair Queueing 알고리즘 비교 분석

이 페이지는 EEVDF(Earliest Eligible Virtual Deadline First) 알고리즘과 Fair Queueing 알고리즘 간의 유사점과 차이점을 분석하고, 특히 세션 지연(session lag) 측면에서 EEVDF의 장점을 설명합니다.

**핵심 내용 요약:**

*   **Fair Queueing 알고리즘과의 유사성:** EEVDF는 Fair Queueing 알고리즘과 이상적인 유체 흐름 모델(idealized fluid-flow model) 및 가상 시간(virtual time) 개념을 공유하여 공정성을 추구합니다.
*   **PFQ(Packet-by-Packet Fair Queueing)와의 비교:** PFQ는 패킷 기반 환경에서 Fair Queueing을 구현한 방식으로, EEVDF와 유사하게 가상 완료 시간(virtual finishing time)을 기준으로 패킷 전송 순서를 결정합니다. 하지만 PFQ는 패킷이 도착 즉시 전송 가능해지는 반면, EEVDF는 동일 세션의 이전 메시지가 모두 전송된 후에만 전송 가능해집니다.
*   **세션 지연 감소 효과:** EEVDF는 PFQ와 달리 세션 내 패킷들을 순차적으로 처리함으로써 세션 지연을 O(n)에서 O(1)로 줄이는 효과를 가집니다. 여기서 n은 활성 세션의 수를 의미합니다.
*   **예시를 통한 설명:** 특정 세션에 높은 가중치가 부여된 환경에서 PFQ는 해당 세션의 패킷을 우선적으로 연속 전송하여 다른 세션의 지연을 증가시키는 반면, EEVDF는 세션 내 패킷 전송을 분산시켜 세션 지연을 줄입니다.
*   **버퍼 요구량 감소:** 세션 지연에 대한 더 강력한 보장은 버퍼 요구량을 줄이는 데 도움이 됩니다. 예를 들어, 수신기가 고정된 시간 간격으로 패킷을 처리하는 경우, 세션 지연이 감소하면 버퍼에 저장해야 하는 패킷 수가 줄어듭니다.
========================
## 논문 요약 정리

이 페이지는 EEVDF(Earliest Eligible Virtual Deadline First) 스케줄링 알고리즘과 다른 비례 공유 스케줄링 알고리즘들을 비교 분석하고 있습니다.

**핵심 내용:**

*   **EEVDF와 다른 스케줄링 알고리즘 비교:** Lottery, Charge-based, BITREV(Bit Reversal), Stride, PD 알고리즘과 EEVDF를 Lag, Quantum, Operation complexity 측면에서 비교합니다.
*   **Lag(지연):** 클라이언트가 받아야 할 서비스 시간과 실제로 받은 서비스 시간의 차이를 나타냅니다.
*   **Quantum(양자):** 알고리즘이 fractional(소수) 및 non-uniform(불균등) 시간 양자를 지원하는지 여부를 나타냅니다.
*   **Operation complexity(연산 복잡도):** 클라이언트 선택, 참여, 이탈, 가중치 변경과 같은 기본적인 동적 연산에 대한 시간 복잡도를 의미합니다.
*   **SCFQ(Self-Clocked Fair Queueing) 언급:** Golestani가 제안한 SCFQ는 PFQ(Packet-by-packet Fair Queueing)를 근사하는 방식으로, 가상 시간을 사용하여 패킷 기반 시스템의 작업 진행 상황을 측정합니다. EEVDF에 SCFQ의 가상 시간 개념을 적용하는 것이 이점이 있을지 불분명하다고 언급합니다.
*   **Lottery Scheduling:** Waldspurger와 Weihl이 제안한 알고리즘으로, 리소스 권한을 lottery tickets(복권 티켓)으로 캡슐화합니다. 각 클라이언트는 특정 수의 티켓을 가지고 있으며, 이는 클라이언트가 받아야 할 리소스의 비율을 결정합니다.
========================
## 논문 요약 정리

이 페이지에서는 다양한 비례 할당 스케줄링 알고리즘들을 소개하고, 각 알고리즘의 특징과 장단점을 분석하고 있습니다.

**1. 로터리 스케줄링 (Lottery Scheduling):**

*   매 타임 슬라이스 시작 시 추첨을 통해 자원 사용 권한을 부여하는 방식입니다.
*   티켓 수에 비례하여 평균적으로 자원을 할당받도록 보장합니다.
*   구현이 간단하고 동적인 작업에 효율적이지만, 클라이언트 지연이 할당된 시간 양자 수의 제곱근에 비례하여 증가하는 단점이 있습니다.

**2. Charge-Based 비례 스케줄링:**

*   프로세서 사용량에 따라 스레드(클라이언트)에 요금을 부과하는 방식입니다.
*   라운드 로빈 방식으로 스레드를 고려하며, 원하는 비율에 가깝게 사용량을 유지하기 위해 일부 스레드를 건너뜁니다.
*   클라이언트 지연은 O(nc)으로 제한되지만, 최악의 경우 선택 연산 복잡도가 O(nc)이며 다른 동적 연산의 시간 복잡도 또한 O(nc)입니다.

**3. 결정적 로터리 스케줄링:**

*   로터리 스케줄링을 개선하기 위해 당첨 번호를 결정론적으로 생성하는 알고리즘입니다.
*   클라이언트 지연을 O(log w)로 제한하지만, 불균일한 시간 양자를 지원하지 않습니다.
*   로터리 스케줄링처럼 정수 비교, 덧셈, 뺄셈만으로 동적 연산을 효율적으로 지원합니다.

**4. 스트라이드 스케줄링 (Stride Scheduling):**

*   네트워크 공정 큐잉 알고리즘을 프로세서 스케줄링에 적용한 것으로 볼 수 있습니다.
*   각 클라이언트는 가중치에 반비례하는 스트라이드와 진행 상황을 측정하는 패스를 가집니다.
*   패스가 가장 낮은 클라이언트에게 시간 양자를 할당하고, 할당 후 패스를 스트라이드만큼 업데이트합니다.
*   기본 알고리즘은 O(nc)의 클라이언트 지연을 보장하며, 클라이언트를 이진 트리로 그룹화하여 계층적으로 적용하면 O(log nc)로 줄일 수 있습니다.

**5. PD 알고리즘:**

*   다중 자원에 대한 비례 공유 스케줄링 알고리즘으로, 클라이언트 지연을 하나의 시간 양자로 제한합니다.
*   단일 자원 환경에서는 클라이언트 선택에 O(log nc)의 시간 복잡도를 가집니다.
*   동적 연산에 대한 명시적인 지원이 부족하여 구현에 O(nc)의 전처리 단계가 필요하며, 분수 및 불균일한 시간 양자를 지원하지 않습니다.
========================
다음은 제시된 논문 페이지의 요약입니다.

**결론**

*   새로운 비례 공유 자원 할당 스케줄러를 제시하며, 이는 유연한 제어와 강력한 시간 보장 기능을 제공합니다. 이 스케줄러는 멀티미디어, 인터랙티브, 배치 애플리케이션 스케줄링을 통합적으로 처리합니다.
*   애플리케이션 요구 사항을 자원 요청 시퀀스로 균일하게 변환하여 이를 달성합니다. 이상적인 시스템과 실제 시스템 간의 서비스 시간 차이를 하나의 시간 양자(time quantum) 내로 제한합니다.
*   이 알고리즘은 클라이언트의 참여/이탈, 가중치 변경과 같은 동적 작업에 효율적인 지원을 제공하며, 분수 및 비균일 시간 양자도 지원합니다.

**향후 연구 방향**

*   EEVDF 위에 더 높은 수준의 자원 추상화를 연구하고, 최소 서비스 보장(inferior bounded service)과 같은 기능을 제공하여 멀티미디어 및 실시간 애플리케이션을 지원하고자 합니다.
*   계층적 및 이기종 스케줄링 방식을 고려합니다. 예를 들어, 클라이언트를 클래스로 그룹화하고, 상위 레벨에서는 비례 스케줄러를 사용하여 클래스에 자원 공유를 할당하고, 하위 레벨에서는 단순 스케줄러(라운드 로빈)를 사용할 수 있습니다.
*   프로세스-스레드 계층 구조에서 비례 스케줄러를 사용하여 각 프로세스에 CPU 시간 슬라이스를 할당하고, 프로세스는 다른 정책을 사용하여 스레드를 선택할 수 있습니다.

**추가 정보**

*   광범위한 시뮬레이션을 수행했으며, FreeBSD Unix에서 프로토타입 구현의 최종 단계에 있습니다. 실험 결과는 추후 논문에서 보고될 예정입니다.
========================
## Strategy 구현 (ANSI C 코드)

이 문서는 Strategy 알고리즘의 ANSI C 코드를 설명하며, 가독성을 위해 클라이언트 데이터 구조 (`client_struct`)와 요청 데이터 구조 (`req_struct`)를 분리하여 사용한다. 실제 구현에서는 하나의 공통 데이터 구조로 통합하는 것이 가능하다.

**핵심 내용:**

*   **데이터 구조:** 클라이언트 정보와 요청 정보를 별도의 구조체로 관리하여 코드의 명확성을 높였다. 실제로는 하나의 구조체로 합쳐 메모리 효율성을 개선할 수 있다.
*   **요청 관리:** 클라이언트의 대기 요청은 트리 기반 데이터 구조 (`ReqTree`)에 저장되며, 삽입, 삭제, 가장 빠른 가상 마감 시간을 가진 요청 검색 연산을 O(log n) 시간에 지원한다. 여기서 n은 활성 클라이언트 수를 나타낸다.
*   **가상 시간 갱신:** 클라이언트가 경쟁에 참여하거나 떠날 때, 또는 가중치가 변경될 때 가상 시간이 업데이트된다.
*   **자원 할당:** `EEVDF_dispatch` 함수는 가장 빠른 마감 시간을 가진 요청을 찾아 해당 클라이언트에게 자원을 할당한다. 요청 처리 시간은 1 time quantum을 넘지 않는다고 가정한다. 만약 요청 시간이 더 길다면, 현재 요청이 완료되기 전에 새 요청을 발행할 필요가 없다.
*   **코드 구조:** 클라이언트 지연 시간 업데이트 (`update_lag`) 및 가상 시간 획득 (`get_current_vt`) 함수는 직접적으로 제공되지는 않지만, 주어진 수식을 기반으로 쉽게 구현할 수 있다.
========================
제공된 코드는 EEVDF(Earliest Eligible Virtual Deadline First) 스케줄링 알고리즘의 핵심 함수들을 구현한 것으로 보입니다. 이 함수들은 클라이언트의 참여, 이탈, 가중치 변경, 그리고 작업 할당을 관리합니다.

**1. join (경쟁 참여)**

*   새로운 클라이언트가 시스템에 참여할 때 호출됩니다.
*   전체 가중치(TotalWeight)를 클라이언트의 가중치(client->weight)만큼 증가시킵니다.
*   클라이언트의 지연 시간(client->lag)을 고려하여 가상 시간(VirtualTime)을 업데이트합니다.
*   클라이언트의 요청(client->req)에 가상 시작 시간(ve)과 가상 마감 시간(vd)을 할당하고, 요청 큐(ReqTree)에 삽입합니다.

**2. leave (경쟁 이탈)**

*   클라이언트가 시스템에서 나갈 때 호출됩니다.
*   전체 가중치를 클라이언트의 가중치만큼 감소시킵니다.
*   클라이언트의 지연 시간을 고려하여 가상 시간을 업데이트합니다.
*   클라이언트의 요청을 요청 큐에서 삭제합니다.

**3. change\_weight (가중치 변경)**

*   클라이언트의 가중치를 변경할 때 호출됩니다.
*   클라이언트의 지연 시간과 이전 가중치를 고려하여 가상 시간을 부분적으로 업데이트합니다.
*   전체 가중치를 새로운 가중치와 이전 가중치의 차이만큼 업데이트합니다.
*   클라이언트의 가중치를 새로운 가중치로 변경하고, 가상 시간을 다시 업데이트합니다.

**4. EEVDF\_dispatch (작업 할당)**

*   가장 빠른 가상 마감 시간을 가진 실행 가능한 요청을 선택합니다.
*   선택된 요청의 클라이언트에게 자원을 할당합니다.
*   클라이언트의 지연 시간을 업데이트합니다.
*   완료된 요청을 요청 큐에서 삭제합니다.
*   클라이언트의 새로운 요청에 가상 시작 시간과 가상 마감 시간을 할당하고, 요청 큐에 삽입합니다.
========================
이 문서는 활성 클라이언트에서 시작된 요청을 효율적으로 관리하기 위한 자료 구조를 제안합니다. 제안하는 자료 구조는 확장된 이진 탐색 트리를 기반으로 하며, 삽입(insert req), 삭제(delete req), 가장 빠른 가상 마감 기한을 가진 적격 요청 찾기(get req) 연산을 지원합니다.

*   **자료 구조**: 확장된 이진 탐색 트리 기반
*   **노드 정보**: 각 노드는 가상 적격 시간(ve), 가상 마감 기한(vd) 및 서브트리 내의 최소 가상 마감 기한(min vd)을 저장
*   **트리 검색**: 가상 적격 시간(ve)을 기준으로 이진 탐색 수행
*   **Get req 연산**: 현재 가상 시간(vtime)을 입력으로 받아 가장 빠른 마감 기한을 가진 적격 요청을 반환
*   **검색 경로**: 루트에서 시작하여 vtime과 노드의 적격 시간을 비교하여 좌/우 자식 노드를 선택하는 방식으로 트리를 탐색
========================
이 페이지는 요청 트리(request tree)에서 가장 빠른 마감 기한(deadline)을 가진 요청을 찾는 알고리즘과 코드를 설명하고 있습니다.

**핵심 내용 요약:**

*   **(a) 요청 트리 검색 경로:** 각 노드에서 가상 적격 시간(virtual eligible time)만을 보여주며, 트리에서 요청을 검색하는 경로를 시각적으로 표현합니다.
*   **(b) 가장 빠른 마감 기한을 가진 노드 검색 코드:** `get_req` 함수는 주어진 가상 시간(`vtime`) 내에 처리 가능한 요청 중 가장 빠른 마감 기한을 가진 요청을 찾는 코드를 보여줍니다.
*   **알고리즘 작동 방식:** 트리를 탐색하면서 `vtime`보다 작거나 같은 가상 적격 시간을 가진 노드를 찾고, 그중 가장 빠른 마감 기한을 가진 노드를 선택합니다. 이때, 탐색 경로상의 노드와 서브트리의 루트를 비교하여 최적의 노드를 찾습니다.
*   **구현:** C언어 스타일의 코드로 구현되어 있으며, 주석을 통해 각 단계의 역할을 설명하고 있습니다.
========================
## 페이지 요약

이 페이지에서는 이진 검색 트리(Binary Search Tree)를 사용하여 요청을 삽입하고 검색하는 알고리즘에 대해 설명합니다. 특히, 마감 기한이 가장 빠른 요청을 효율적으로 찾는 방법에 초점을 맞추고 있습니다.

**핵심 내용:**

*   **Eligible 노드**: 현재 노드의 `vtime`이 해당 노드의 eligible time보다 크면, 현재 노드와 모든 왼쪽 자손 노드는 eligible 상태가 됩니다. 이는 왼쪽 파티션에서 마감 기한이 가장 빠른 노드를 찾는 데 중요합니다.
*   **검색 변수**: 마감 기한이 가장 빠른 eligible 노드를 찾기 위해 `path_req` (검색 경로 상의 eligible 노드 중 마감 기한이 가장 빠른 노드)와 `st_tree` (왼쪽 파티션에서 `min_vd`가 가장 작은 서브 트리의 루트)라는 두 가지 주요 변수를 사용합니다.
*   **삽입 알고리즘**: 새로운 요청을 삽입하는 `insert_req` 함수는 일반적인 이진 검색 트리 삽입 알고리즘과 유사하지만, 새로운 노드의 모든 조상 노드의 `min_vd` 필드를 업데이트해야 합니다. 이는 트리의 효율적인 검색을 위해 필요합니다.
*   **min_vd**: 각 노드는 자신의 서브 트리에서 가장 작은 마감 기한(`min_vd`)을 저장합니다. 이를 통해 마감 기한이 가장 빠른 요청을 찾는 검색 범위를 좁힐 수 있습니다.
*   **최적 요청**: 최종적으로 `path_req` 또는 `st_tree`에 속한 노드 중 하나가 마감 기한이 가장 빠른 요청이 됩니다. 알고리즘은 이 두 후보를 비교하여 최종 결과를 반환합니다.
========================
## 이진 검색 트리(BST) 삭제 및 min_vd 업데이트

이 페이지에서는 이진 검색 트리(BST)에서 노드를 삭제하는 알고리즘과 삭제 후 트리의 `min_vd` 값을 업데이트하는 방법에 대해 설명합니다. `min_vd`는 노드의 가상 데드라인(virtual deadline)과 자식 노드의 `min_vd` 값 중 최솟값을 저장하는 필드입니다.

**1. 삭제 알고리즘**

삭제 알고리즘은 삭제할 노드의 자식 수에 따라 세 가지 경우로 나뉩니다.

*   **경우 1: 삭제할 노드가 리프 노드인 경우**
    *   단순히 노드를 삭제합니다.
*   **경우 2: 삭제할 노드가 자식 노드를 하나만 가진 경우**
    *   삭제된 노드의 부모 노드가 자식 노드를 상속받도록 연결을 변경합니다.
*   **경우 3: 삭제할 노드가 자식 노드를 두 개 가진 경우**
    *   삭제할 노드의 successor(중위 순회 시 바로 다음 노드)를 찾습니다.
    *   successor를 삭제하고, 삭제된 노드의 위치에 successor를 복사합니다.

**2. `backward_update` 함수**

노드 삭제 후에는 삭제된 노드의 조상 노드들의 `min_vd` 값을 업데이트해야 합니다. 이를 위해 `backward_update` 함수가 사용됩니다.

*   `backward_update` 함수는 삭제된 노드의 부모 노드부터 시작하여 루트 노드까지 거슬러 올라가면서 각 노드의 `min_vd` 값을 갱신합니다.
*   각 노드의 `min_vd` 값은 해당 노드의 가상 데드라인(`vd`)과 자식 노드들의 `min_vd` 값 중 가장 작은 값으로 설정됩니다.
*   이 과정을 통해 삭제로 인해 변경된 데드라인 정보가 트리의 상위 노드들에게 전파됩니다.

**3. Successor**

*   이진 검색 트리에서 노드 n의 successor는 n의 키보다 큰 키를 가진 노드 중 가장 작은 키를 가진 노드로 정의됩니다.
*   successor는 삭제 연산에서 삭제할 노드가 두 개의 자식을 가질 때, 삭제될 노드를 대체하는 데 사용됩니다.
*   successor를 찾는 과정은 삭제 연산의 복잡도를 증가시키는 요인이 될 수 있습니다.
========================
제공된 코드는 이진 트리의 노드 삭제 연산을 구현한 것입니다. 삭제 연산은 삭제할 노드의 자식 노드 수에 따라 세 가지 경우로 나뉩니다.

**삭제 연산의 핵심 내용:**

*   **(i) 및 (ii) 경우: 자식 노드가 없거나 하나인 경우**
    *   삭제할 노드의 자식 노드를 가져옵니다.
    *   자식 노드가 있다면, 자식 노드의 부모를 삭제할 노드의 부모로 설정합니다.
    *   삭제할 노드가 루트 노드인 경우, 자식 노드를 새로운 루트 노드로 반환합니다.
    *   삭제할 노드가 루트 노드가 아니라면, 삭제할 노드의 부모 노드의 왼쪽 또는 오른쪽 자식을 자식 노드로 설정합니다.
    *   삭제할 노드의 조상 노드들의 `min_vd` 값을 갱신합니다.

*   **(iii) 경우: 자식 노드가 두 개인 경우**
    *   삭제할 노드의 successor(중위 순회 시 다음 노드)를 찾습니다.
    *   successor를 트리에서 삭제합니다.
    *   삭제할 노드와 successor의 위치를 바꿉니다.
    *   삭제할 노드의 조상 노드들의 `min_vd` 값을 갱신합니다.

*   **전체적인 흐름**
    *   `delete_req` 함수는 삭제할 노드(`req`)와 루트 노드(`root`)를 입력으로 받습니다.
    *   삭제할 노드의 자식 노드 수에 따라 위에서 설명한 세 가지 경우 중 하나를 수행합니다.
    *   삭제 연산 후, 루트 노드를 반환합니다.
    *   `backward_update` 함수는 삭제 연산 후 조상 노드들의 `min_vd` 값을 갱신하는 역할을 합니다.
    *   `get_child`, `get_successor`, `swap_node` 등의 함수는 각각 자식 노드 가져오기, successor 찾기, 노드 위치 바꾸기 등의 역할을 수행합니다.
========================
## 논문 요약: 이진 탐색 트리 및 균형 트리에서의 연산

이 페이지에서는 이진 탐색 트리(Binary Search Tree)에서의 삭제 연산과 균형 트리의 필요성, 그리고 균형을 맞추기 위한 회전 연산에 대해 설명합니다.

**1. 이진 탐색 트리 삭제 연산 (delete_req):**

*   `delete_req` 함수는 최대 한 번만 재귀적으로 호출되어 효율성을 높입니다.
*   함수는 전체 트리가 아닌 삭제 대상 노드의 오른쪽 하위 트리에서만 작동하여 `min_vd` 필드를 업데이트합니다.
*   삭제 후에는 successor 노드로 대체하고, backward update 함수를 호출하여 ancestor 노드들의 `min_vd` 필드를 갱신합니다.
*   높이가 h인 트리에서 `get_req`, `insert_req`, `delete_req` 함수의 시간 복잡도는 O(h)입니다.

**2. 균형 트리의 필요성:**

*   일반적인 이진 탐색 트리는 평균적으로 좋은 성능을 보이지만, 최악의 경우(트리가 한쪽으로 치우쳐진 경우) 삽입, 삭제, 검색 연산의 시간 복잡도가 O(n)이 될 수 있습니다.
*   이러한 문제를 해결하기 위해 레드-블랙 트리(Red-Black Tree)나 AVL 트리와 같은 균형 잡힌 데이터 구조를 사용합니다.

**3. 균형 트리 회전 연산:**

*   균형 트리는 삽입 또는 삭제 후 트리의 균형을 유지하기 위해 좌/우 회전(rotation) 연산을 수행합니다.
*   회전 연산은 상수 시간이 소요되며, n개의 노드를 가진 트리의 균형을 맞추는 데 O(log n)의 시간 복잡도가 필요합니다.
*   따라서 균형 트리를 사용할 경우 `get_req`, `insert_req`, `delete_req` 함수의 전체 시간 복잡도는 O(log n)으로 개선됩니다.
*   그림 5는 좌측 회전 시 노드의 상태를 업데이트하는 코드를 보여줍니다. (우측 회전 코드도 유사함)
========================
이 문서는 운영체제 및 스케줄링 관련 참고 문헌 목록입니다. 각 항목은 논문, 서적, 기술 보고서 등을 나타내며, 저자, 제목, 발표 장소, 출판사, 발표 연도, 페이지 번호 등의 정보를 포함합니다.

**핵심 내용 요약:**

*   다양한 운영체제 설계 및 구현 방식 (Unix, SPIN, Exokernel)을 다룬다.
*   실시간 시스템 및 멀티미디어 컴퓨팅을 위한 스케줄링 알고리즘 (Rate Monotonic Scheduling, Fair Queueing)을 소개한다.
*   네트워크 지연 분석 및 QoS (Quality of Service) 제어 관련 연구를 포함한다.
*   자원 관리 및 서비스 품질 보장을 위한 다양한 접근 방식을 제시한다.
*   참고 문헌들은 운영체제, 실시간 시스템, 네트워크 분야의 학문적 연구에 기여한 중요한 자료들이다.
========================
이 페이지는 다양한 논문들을 참고 문헌으로 나열하고 있습니다. 각 논문은 특정 기술 분야, 특히 운영체제, 네트워크, 멀티미디어 시스템 등에서 자원 관리, 스케줄링, 트래픽 제어 등에 대한 연구를 다루고 있습니다.

**핵심 내용 요약:**

*   **자원 관리 및 스케줄링:** 여러 논문이 프로세서 용량 예약(Processor Capacity Reserves), 비례 공유 스케줄링(Proportional Share Scheduling), Lottery Scheduling, Stride Scheduling 등 다양한 스케줄링 기법을 다루고 있습니다. 이러한 기법들은 시스템 자원을 공정하고 효율적으로 할당하는 데 초점을 맞추고 있습니다.
*   **멀티미디어 시스템 지원:** 일부 논문은 멀티미디어 애플리케이션을 위한 운영체제 지원 및 통합 프로세서 스케줄링에 대해 연구하고 있습니다. 이는 멀티미디어 애플리케이션의 실시간 요구 사항을 충족시키기 위한 기술들을 포함합니다.
*   **네트워크 트래픽 제어:** Virtual Clock 알고리즘과 같은 네트워크 트래픽 제어 기법에 대한 연구도 언급되어 있습니다. 이는 네트워크 혼잡을 방지하고 서비스 품질을 보장하기 위한 기술입니다.

# 최종요약

## EEVDF (Earliest Eligible Virtual Deadline First) 알고리즘 논문 종합 요약

이 논문은 **시간 공유 자원**에 대한 새로운 **비례 공유 할당 알고리즘**인 EEVDF를 제안하고 분석합니다. EEVDF는 **유연한 제어**와 **강력한 시간 보장** 기능을 제공하여 멀티미디어, 인터랙티브, 배치 애플리케이션 스케줄링을 통합적으로 처리하는 것을 목표로 합니다.

**핵심 아이디어:**

*   **비례 공유 할당:** 각 클라이언트에게 **가중치**를 부여하여 자원의 상대적인 점유율을 결정합니다. 가중치가 높은 클라이언트는 더 많은 자원을 할당받습니다.
*   **가상 시간 기반 스케줄링:** 실제 시간 대신 **가상 시간**을 사용하여 스케줄링 결정을 내립니다. 가상 시간은 활성 클라이언트의 가중치 합계에 반비례하는 속도로 증가하며, 경쟁이 심화되면 느려지고, 경쟁이 줄어들면 빨라집니다.
*   **적격 시간과 마감 시간:** 각 요청에 대해 **가상 적격 시간(eligible time)**과 **가상 마감 시간(deadline)**을 할당합니다. 가상 적격 시간은 이상적인 시스템에서 클라이언트가 받아야 할 서비스 시간과 실제 시스템에서 이미 받은 서비스 시간이 같아지는 시점으로 설정됩니다. EEVDF는 가상 마감 시간이 가장 빠른 요청부터 처리합니다.
*   **서비스 시간 지연(Service Time Lag) 최소화:** 클라이언트가 받아야 할 서비스 시간과 실제로 받은 서비스 시간의 차이(지연)를 **시간 양자(time quantum) 크기(q)**로 제한하여 공정성을 보장합니다.
*   **동적 운영 지원:** 클라이언트의 참여, 종료, 가중치 변경과 같은 동적인 상황을 지원하며, 이러한 이벤트 발생 시 가상 시간을 업데이트하여 공정성을 유지합니다.
*   **효율적인 구현:** **확장된 이진 탐색 트리** 자료 구조를 사용하여 이러한 동적 운영을 O(log n) 시간 복잡도로 효율적으로 구현합니다 (n은 자원 경쟁 클라이언트 수).

**EEVDF의 장점:**

*   **유연하고 정확한 비율 공유 자원 할당:** 티켓, 통화, 프로세서 용량 예약과 같은 상위 수준 자원 추상화 지원
*   **강력한 실시간성 보장:** 서비스 시간에 대한 강력한 실시간성 보장
*   **통합된 접근 방식:** 연속 미디어, 인터랙티브, 배치 애플리케이션 스케줄링을 위한 통합된 접근 방식 제공
*   **동적 작업 효율적 구현:** 티켓 전송 및 소멸과 같은 동적 작업 효율적으로 구현
*   **세션 지연 감소:** 세션 내 패킷들을 순차적으로 처리함으로써 세션 지연을 줄이는 효과
*   **시간 양자화 환경에서의 최적성:** 시간 양자 크기(q)보다 큰 요청이 없는 경우, 클라이언트의 지연은 `-q < lag_k(t) < q`로 제한되어 비례 공유 알고리즘에서 달성할 수 있는 최적의 경계를 제공

**기존 스케줄러와의 비교:**

*   기존 실시간 스케줄러는 배치 애플리케이션에 적용하기 어렵고, 엄격한 허용 정책으로 인해 사용자가 새로운 애플리케이션을 실행하기 어려울 수 있습니다.
*   EEVDF는 이러한 한계를 극복하고, 실시간성과 공정성을 동시에 보장합니다.
*   Fair Queueing 알고리즘과 유사하지만, 세션 지연 측면에서 EEVDF가 더 우수한 성능을 보입니다.

**구현 및 분석:**

*   논문은 EEVDF 알고리즘, 동적 시스템에서의 공정성 개념, EEVDF 알고리즘 구현 전략, 공정성 분석, 관련 연구 검토, 결론 순으로 구성됩니다.
*   확장된 이진 탐색 트리를 사용하여 효율적인 구현을 제시하고, 시간 복잡도를 분석합니다.
*   클라이언트의 지연 시간을 제한하는 경계를 분석하고, 요청 크기와 시스템 오버헤드 간의 관계를 설명합니다.
*   다양한 비례 할당 스케줄링 알고리즘들과 비교 분석합니다.

**향후 연구 방향:**

*   EEVDF 위에 더 높은 수준의 자원 추상화를 연구하고, 최소 서비스 보장과 같은 기능을 제공하여 멀티미디어 및 실시간 애플리케이션을 지원하고자 합니다.
*   계층적 및 이기종 스케줄